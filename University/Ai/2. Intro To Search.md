To solve a maze we must find a **path** from an initial location to a goal location. A path is determined by a sequence of choices. At each **choice-point** we must choose between two or more **branches**.

E.g Of Search Problems:
- Puzzles, i.e. Mazes, Rubik's Cube
- Route Finding, Motion Control
- Activity Planning, Games AI
- Scheduling 
- Mathematical Theorem Proving
- Design Of Computer Chips, Drugs, Buildings

<h4>State Spaces</h4>
In  the maze example, search takes place within the physical space. We want to find a path connecting physical locations.
Can apply the general idea of search to more abstract kinds of problem. To do this we replace the physical space with a **state space**.

The states in the space can correspond to any kind of configuration. For example, the possible settings of a device, positions in a game or a set of assignments to variables.

Paths in state space correspond to possible sequences of **transitions** between states.

<h4>Search Space</h4>
Essentially just a state space, in which we have an **initial state** and one or more **goal states**.

Given a search space, a solution to the search problem is a path consisting of a sequence of connected states, starting at the initial state and ending at one of the goal states.
<h4>Type Of Search Problem</h4>
Find a solution:
- Search for a state or configuration satisfying the known conditions
Find a plan or path leading to a solution/goal:
- Search for a sequence of steps (actions) that lead from an initial state to a desired goal state.
Find an optimal solution:
- Many problems have multiple solutions. In such cases there can be preference of some solutions being better than others. If so we would naturally be interested in finding the best solution
Find an optimal path to a goal:
- Often want to find an optimal sequence of steps (actions) that lead from an initial state to a goal state. An optimal sequence is one that has the lowest 'cost' (takes the least time or resources). In many cases will consider the optimal solution to be the one that is achievable with the least cost

If one tries to find a solution without considering how it can be constructed, only applicable method would be to try all possible configurations and check whether each is indeed a solution. Called a **brute force** approach.

Huge variety of problems can be cast into the form of search problems. In order to apply a search approach we need to analyse the problem as follows:
- Conceptualise possible solutions and intermediate stages towards solutions as **states** (and identify initial state)
- Identify transitions that allow a state to be transformed into other successor states
- Devise an algorithm that will systematically search through possible paths from initial state in order to find a path that ends in a goal
<h4>Search Tree</h4>
The state space associate with a problem can in general be an arbitrary graph. Each node is a state and each arc represents a possible transition between states.
However in devising a search algorithm we normally treat the search space as if it were a **tree**.
Root node is initial state.
Children of each state/node *S* are all those states/nodes that are reachable *S* by a single transition.

For certain problems we may actually have a tree (or graph) structure stored as data - i.e. have an explicit representation of the search space.

In many cases the search space is not explicitly represented, rather a search tree is generated during the execution of the search algorithm.

To generate such a tree one needs an algorithm or set of rules which, given any state, can return a list of all possible successor states.

In order to implement a search algorithm, we need a way of determining the possible successors to any given state. Several ways to do this:
- Set up data structure (tree / graph) that explicitly represents the successor relation
- Give set of actions and specify in what kinds of state they can be executed, and how they transform the state to a new state
- Specify a way of choosing a possible next state and also a set of conditions to determine whether that state is indeed possible

In general don't necessarily know whether path we are on will lead to a solution. May just have to keep going and see if we eventually get to a goal state.
However, may get to dead end - state with no successors.
Alternatively we may come to a state that we have already been in - in a loop. 
Search algorithms most efficient and easy to implement if there are simple ways to test if we have reached a dead end or loop.

<h4>Breadth-First Search</h4>
Start at root and explore the tree by working down level by level. Testing each path to see if we have reached goal. ![[Pasted image 20250131141740.png]]
<h4>Depth-First Search</h4>
Follow a single path down as deep as we can go until either reach a goal or dead end. In latter case we 'backtrack' up the path until we reach a branch that has not yet been tried. Then search down new branch.![[Pasted image 20250131141843.png]]
<h4>Search For Optimal Solutions</h4>
Certain problems don't want only a solution but want best possible.
In order to tell what is optimal solution, need some kind of measure of how good solution is.
In some cases this measure is determined by goal state itself (e.g. the timetable with fewest 9 o'clock lectures is best).
In cases where we are more interested in the path to the solution, typically want to find a path that is the quickest, easiest or cheapest to carry out.
Typically we assign a cost to each transition, and cost of a path is simply sum of costs of each transition in the path.